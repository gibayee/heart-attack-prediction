{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix,ConfusionMatrixDisplay, precision_recall_fscore_support, precision_score, recall_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rs=123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\HP\\Desktop\\Online Courses\\IBM Machine Learning Engineer\\2. Classification\\All data\\heartattack.csv\", na_values='?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring and Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general info of columns\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of data types\n",
    "data.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To keep the cleaning process simple, we’ll remove:\n",
    "# the columns with many missing values, which are slope, ca, thal.\n",
    "# the rows with missing values.\n",
    "\n",
    "data = data.drop(['slope', 'ca', 'thal'], axis=1)\n",
    "\n",
    "data = data.dropna().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #check data types of columns with missing values\n",
    "# columns=list(data.columns)\n",
    "# col_mv=[]\n",
    "# for col in columns:\n",
    "#     if data[col].isnull().sum()>0:\n",
    "#         col_mv.append(col)\n",
    "# col_mv\n",
    "# data[col_mv].dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # replace all missing values with means of respective columns\n",
    "# for col in col_mv:\n",
    "#     data[col] = data[col].fillna(data[col].mean())\n",
    "# data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outliers\n",
    "numeric_columns = list(data.select_dtypes(include=[np.number]).columns)\n",
    "len(numeric_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(numeric_columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #box plot\n",
    "# # lets resolve this issue later\n",
    "# ncols=3\n",
    "# nrows=math.ceil(len(numeric_columns)/ncols)\n",
    "# fig, axes = plt.subplots(nrows, ncols, figsize=(15, 6))  # Create subplots\n",
    "\n",
    "# for i, column in enumerate(numeric_columns):\n",
    "#     axes[i].boxplot(data[column])  # Create a box plot for the column in the i-th subplot\n",
    "#     axes[i].set_title(f'Box Plot for {column}')  # Set the title for the subplot\n",
    "#     axes[i].set_xlabel(column)  # Set the x-axis label\n",
    "\n",
    "# plt.tight_layout()  # Adjust subplot layout for better spacing\n",
    "# plt.show()  # Display the figure with subplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #using z-score\n",
    "\n",
    "# treshold=3\n",
    "# for column in numeric_columns:\n",
    "#     # Calculate the z-scores\n",
    "#     z_scores = stats.zscore(data[column])\n",
    "    \n",
    "#     # Find the rows where z-scores are greater than treshold\n",
    "#     outliers = np.abs(z_scores) > treshold\n",
    "    \n",
    "#     # Replace outliers with the mean value of the column\n",
    "#     mean_value = data[column].mean()\n",
    "#     data.loc[outliers, column] = mean_value\n",
    "\n",
    "# # Now, data contains the data with outliers replaced by the mean value for each numeric column\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming target variable\n",
    "data = data.rename(columns={'num       ': 'heart_attack'})\n",
    "\n",
    "data['heart_attack'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# age: age in years\n",
    "# sex: sex (1 = male; 0 = female)\n",
    "# cp: chest pain type\n",
    "# – 1: typical angina\n",
    "# – 2: atypical angina\n",
    "# – 3: non-anginal pain\n",
    "# – 4: asymptomatic\n",
    "# trestbps: resting blood pressure (in mm Hg on admission to the hospital)\n",
    "# chol: serum cholesterol in mg/dl\n",
    "# fbs: (fasting blood sugar > 120 mg/dl) (1 = true; 0 = false)\n",
    "# restecg: resting electrocardiographic results\n",
    "# – 0: normal\n",
    "# – 1: having ST-T wave abnormality (T wave inversions and/or ST elevation or depression of > 0.05 mV)\n",
    "# – 2: showing probable or definite left ventricular hypertrophy by Estes’ criteria\n",
    "# thalach: maximum heart rate achieved\n",
    "# exang: exercise-induced angina (1 = yes; 0 = no)\n",
    "# oldpeak: ST depression induced by exercise relative to rest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Categorical Variables: Creating Dummy Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Among the five categorical variables, sex, fbs, and exang only have two levels of 0 and 1, \n",
    "# so they are already in the dummy variable format. But we still need to convert cp and restecg \n",
    "# into dummy variables\n",
    "\n",
    "print(data['cp'].value_counts(dropna=False))\n",
    "\n",
    "print(data['restecg'].value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(data, columns=['cp', 'restecg'], drop_first=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can print out the numeric columns and categorical columns as numeric_cols and cat_cols below.\n",
    "\n",
    "numeric_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak']\n",
    "cat_cols = list(set(data.columns) - set(numeric_cols) - {'target'})\n",
    "cat_cols.sort()\n",
    "\n",
    "print(numeric_cols)\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the Numerical Variables: Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "for i in numeric_cols:\n",
    "    data[i]=scaler.fit_transform(data[[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Target and Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['heart_attack']\n",
    "X=data.drop(columns='heart_attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Training and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when the dataset is imbalanced, it’s good practice to do stratified sampling. In this way, both the training and test datasets will have similar portions of the target classes as the complete dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's split the training and testing dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state =rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='none') # logistic regression with no penalty term in the cost function.\n",
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluations(y, yhat):\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    precision, recall, f_beta, _ = precision_recall_fscore_support(y_test, predictions)\n",
    "    print('Accuracy Score = {}'.format(accuracy))\n",
    "    print('Precision Score = {}'.format(precision))\n",
    "    print('Recall Score = {}'.format(recall))\n",
    "    print('f_beta Score = {}'.format(f_beta))\n",
    "evaluations(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm=confusion_matrix(y_test, predictions, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_context('talk')\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,display_labels=model.classes_)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
